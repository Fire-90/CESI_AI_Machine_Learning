# ğŸ¤– CESI AI Machine Learning - PrÃ©diction de l'Attrition des EmployÃ©s

Projet d'analyse prÃ©dictive visant Ã  identifier les facteurs de dÃ©part des employÃ©s et Ã  comparer diffÃ©rents algorithmes de Machine Learning pour prÃ©dire l'attrition.

---

## ğŸ“‹ Table des MatiÃ¨res

- [Objectifs du Projet](#-objectifs-du-projet)
- [Structure du Projet](#-structure-du-projet)
- [DonnÃ©es](#-donnÃ©es)
- [MÃ©thodologie](#-mÃ©thodologie)
- [ModÃ¨les ImplÃ©mentÃ©s](#-modÃ¨les-implÃ©mentÃ©s)
- [Installation](#-installation)
- [Utilisation](#-utilisation)
- [Ã‰thique et ConformitÃ©](#-Ã©thique-et-conformitÃ©)
- [RÃ©sultats Attendus](#-rÃ©sultats-attendus)

---

## ğŸ¯ Objectifs du Projet

1. **PrÃ©dire l'attrition** : DÃ©velopper des modÃ¨les capables de prÃ©dire si un employÃ© risque de quitter l'entreprise
2. **Identifier les facteurs clÃ©s** : DÃ©terminer les variables les plus influentes dans la dÃ©cision de dÃ©part
3. **Comparer les algorithmes** : Ã‰valuer et comparer au minimum 8 modÃ¨les de Machine Learning diffÃ©rents
4. **Fournir des insights actionnables** : Aider les RH Ã  prendre des dÃ©cisions Ã©clairÃ©es pour amÃ©liorer la rÃ©tention

---

## ğŸ“ Structure du Projet

```
CESI_AI_Machine_Learning/
â”‚
â”œâ”€â”€ data/                                    # DonnÃ©es brutes et traitÃ©es
â”‚   â”œâ”€â”€ employee_survey_data.csv            # EnquÃªte satisfaction employÃ©s
â”‚   â”œâ”€â”€ manager_survey_data.csv             # Ã‰valuation des managers
â”‚   â”œâ”€â”€ general_data.csv                    # DonnÃ©es dÃ©mographiques et contractuelles
â”‚   â”œâ”€â”€ in_time.csv                         # Horaires d'arrivÃ©e (badgeuse)
â”‚   â”œâ”€â”€ out_time.csv                        # Horaires de dÃ©part (badgeuse)
â”‚   â”œâ”€â”€ processed_hr_data.csv               # DonnÃ©es consolidÃ©es
â”‚   â”œâ”€â”€ processed_hr_data_encoded_raw.csv   # DonnÃ©es encodÃ©es (non normalisÃ©es)
â”‚   â””â”€â”€ processed_hr_data_encoded_normalized.csv  # DonnÃ©es encodÃ©es et normalisÃ©es
â”‚
â”œâ”€â”€ Traitement.ipynb                        # Pipeline de traitement des donnÃ©es
â”œâ”€â”€ Modele.ipynb                            # ImplÃ©mentation et comparaison des modÃ¨les
â”œâ”€â”€ Plan_action.txt                         # Plan dÃ©taillÃ© du projet
â””â”€â”€ README.md                               # Documentation (ce fichier)
```

---

## ğŸ“Š DonnÃ©es

### Sources de DonnÃ©es

Le projet utilise 5 fichiers sources distincts :

1. **general_data.csv** : Informations dÃ©mographiques, salaire, poste, anciennetÃ©
2. **manager_survey_data.csv** : Ã‰valuations de performance, implication
3. **employee_survey_data.csv** : Satisfaction environnement, Ã©quilibre vie pro/perso
4. **in_time.csv / out_time.csv** : DonnÃ©es de badgeuse (annÃ©e complÃ¨te)

### Variables CrÃ©Ã©es

- **AverageWorkingHours** : Moyenne des heures travaillÃ©es par jour
- **TotalWorkingDays** : Nombre total de jours travaillÃ©s dans l'annÃ©e

### Traitement AppliquÃ©

- âœ… Fusion des 5 sources de donnÃ©es via `EmployeeID`
- âœ… Suppression des colonnes Ã  valeur unique (sans variance)
- âœ… Gestion des valeurs manquantes (imputation par la moyenne)
- âœ… Encodage des variables catÃ©gorielles (Ordinal + One-Hot)
- âœ… Normalisation Min-Max (0-1) pour certains modÃ¨les

---

## âš™ï¸ MÃ©thodologie

### 1. Traitement des DonnÃ©es
- **Normalisation** : MinMaxScaler pour mettre toutes les variables entre 0 et 1
- **Encodage** :
  - Ordinal pour `BusinessTravel` (Non < Rarely < Frequently)
  - One-Hot pour `Department`, `EducationField`, `Gender`, `JobRole`, `MaritalStatus`
- **Nettoyage** : Suppression des variables sans variance (ex: `Over18`, `StandardHours`)

### 2. Choix des ModÃ¨les (minimum 8)
- XGBoost
- K-Nearest Neighbors (KNN)
- Support Vector Machine (SVM)
- Perceptron
- Random Forest
- RÃ©gression Logistique
- RÃ©seaux de Neurones
- *(autres Ã  ajouter selon les besoins)*

### 3. Ã‰valuation des ModÃ¨les
- **MÃ©triques** : Accuracy, Precision, Recall, F1-Score
- **Visualisations** :
  - Matrice de confusion
  - Courbes ROC et AUC
  - Diagrammes de barres (comparaison des modÃ¨les)
  - Heatmap (corrÃ©lations)
  - Feature Importance (variables les plus influentes)

### 4. PrÃ©vention du Sur/Sous-Apprentissage
- Validation croisÃ©e (K-Fold Cross-Validation)
- SÃ©paration Train/Test (80/20 ou 70/30)
- Techniques d'ensemble (Bagging, Boosting)
- RÃ©gularisation (L1, L2)

---

## ğŸ¤– ModÃ¨les ImplÃ©mentÃ©s

### Fichiers NormalisÃ©s vs Non-NormalisÃ©s

| ModÃ¨le | Fichier RecommandÃ© | Raison |
|--------|-------------------|---------|
| XGBoost | `encoded_raw.csv` | BasÃ© sur des arbres, insensible Ã  l'Ã©chelle |
| Random Forest | `encoded_raw.csv` | BasÃ© sur des arbres, insensible Ã  l'Ã©chelle |
| KNN | `encoded_normalized.csv` | Sensible aux distances euclidiennes |
| SVM | `encoded_normalized.csv` | NÃ©cessite des donnÃ©es normalisÃ©es |
| RÃ©gression Logistique | `encoded_normalized.csv` | Performance amÃ©liorÃ©e avec normalisation |
| RÃ©seaux de Neurones | `encoded_normalized.csv` | Convergence plus rapide avec normalisation |
| Perceptron | `encoded_normalized.csv` | NÃ©cessite des donnÃ©es normalisÃ©es |

---