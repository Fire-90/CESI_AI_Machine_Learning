# ğŸ¤– CESI AI Machine Learning - PrÃ©diction de l'Attrition des EmployÃ©s

Projet d'analyse prÃ©dictive visant Ã  identifier les facteurs de dÃ©part des employÃ©s et Ã  comparer diffÃ©rents algorithmes de Machine Learning pour prÃ©dire l'attrition.

---

## ğŸ“‹ Table des MatiÃ¨res

- [Objectifs du Projet](#-objectifs-du-projet)
- [Structure du Projet](#-structure-du-projet)
- [Pipeline de Traitement](#-pipeline-de-traitement)
- [Analyse Exploratoire](#-analyse-exploratoire)
- [ModÃ¨les ImplÃ©mentÃ©s](#-modÃ¨les-implÃ©mentÃ©s)
- [MÃ©triques d'Ã‰valuation](#-mÃ©triques-dÃ©valuation)

---

## ğŸ¯ Objectifs du Projet

1. **PrÃ©dire l'attrition** : DÃ©velopper des modÃ¨les capables de prÃ©dire si un employÃ© risque de quitter l'entreprise
2. **Identifier les facteurs clÃ©s** : DÃ©terminer les variables les plus influentes dans la dÃ©cision de dÃ©part via Feature Importance
3. **Comparer les algorithmes** : Ã‰valuer et comparer 9 modÃ¨les de Machine Learning diffÃ©rents
4. **Fournir des insights actionnables** : Aider les RH Ã  prendre des dÃ©cisions Ã©clairÃ©es pour amÃ©liorer la rÃ©tention
5. **Analyser visuellement** : GÃ©nÃ©rer des graphiques pour diagnostiquer les causes de dÃ©part

---

## ğŸ“ Structure du Projet

```
CESI_AI_Machine_Learning/
â”‚
â”œâ”€â”€ data/                                    # DonnÃ©es brutes et traitÃ©es
â”‚   â”œâ”€â”€ employee_survey_data.csv            # EnquÃªte satisfaction employÃ©s
â”‚   â”œâ”€â”€ manager_survey_data.csv             # Ã‰valuation des managers
â”‚   â”œâ”€â”€ general_data.csv                    # DonnÃ©es dÃ©mographiques et contractuelles
â”‚   â”œâ”€â”€ in_time.csv                         # Horaires d'arrivÃ©e (badgeuse)
â”‚   â”œâ”€â”€ out_time.csv                        # Horaires de dÃ©part (badgeuse)
â”‚   â”œâ”€â”€ processed_hr_data.csv               # DonnÃ©es consolidÃ©es et nettoyÃ©es
â”‚   â”œâ”€â”€ processed_hr_data_encoded_raw.csv   # DonnÃ©es encodÃ©es (non normalisÃ©es)
â”‚   â””â”€â”€ processed_hr_data_encoded_normalized.csv  # DonnÃ©es encodÃ©es et normalisÃ©es
â”‚
â”œâ”€â”€ picture/                                # Images pour la documentation
â”‚   â”œâ”€â”€ SVM.webp                           # Diagramme SVM
â”‚   â”œâ”€â”€ KNN.png                            # Diagramme KNN
â”‚   â”œâ”€â”€ NAIVEBAYES.webp                    # Diagramme Naive Bayes
â”‚   â”œâ”€â”€ DESICIONTREE.png                   # Diagramme Decision Tree
â”‚   â”œâ”€â”€ RANDOMFOREST.jpg                   # Diagramme Random Forest
â”‚   â”œâ”€â”€ XGBOOST.png                        # Diagramme XGBoost
â”‚   â””â”€â”€ RESEAUNEURONES.png                 # Diagramme RÃ©seau de Neurones
â”‚
â”œâ”€â”€ Traitement.ipynb                        # Pipeline complet de traitement des donnÃ©es
â”œâ”€â”€ Modele.ipynb                            # ImplÃ©mentation et comparaison des 9 modÃ¨les
â”œâ”€â”€ Plan_action.txt                         # Plan dÃ©taillÃ© du projet
â””â”€â”€ README.md                               # Documentation (ce fichier)
```

---

## ğŸ”„ Pipeline de Traitement

### Ã‰tape 1 : Consolidation des DonnÃ©es (`process_hr_data()`)

**Objectif** : Centraliser les donnÃ©es dispersÃ©es dans 5 fichiers CSV et crÃ©er de nouvelles variables.

#### Sources de DonnÃ©es

1. **general_data.csv** : Informations dÃ©mographiques, salaire, poste, anciennetÃ©
2. **manager_survey_data.csv** : Ã‰valuations de performance, implication
3. **employee_survey_data.csv** : Satisfaction environnement, Ã©quilibre vie pro/perso
4. **in_time.csv** : Horaires d'arrivÃ©e (badgeage entrant) - 365 jours
5. **out_time.csv** : Horaires de dÃ©part (badgeage sortant) - 365 jours

#### Fusion et Feature Engineering

- **Fusion** : Utilisation de `EmployeeID` comme clÃ© de jointure (Left Merge)
- **Calcul de mÃ©triques temporelles** :
  - `AverageWorkingHours` : Moyenne des heures travaillÃ©es par jour (excluant les absences)
  - `TotalWorkingDays` : Nombre total de jours badgÃ©s dans l'annÃ©e
- **Nettoyage** : Suppression des colonnes Ã  valeur unique (ex: `Over18='Y'`, `StandardHours=8`)

**Sortie** : `processed_hr_data.csv` (donnÃ©es consolidÃ©es)

---

### Ã‰tape 2 : Encodage et Normalisation

**Objectif** : Transformer les donnÃ©es textuelles en numÃ©riques et gÃ©nÃ©rer deux versions du dataset.

#### Traitement de la Cible

- `Attrition` : Conversion binaire (Yes â†’ 1 / No â†’ 0)

#### Encodage des Variables CatÃ©gorielles

**Variables Ordinales** (ordre important) :
- `BusinessTravel` : Non-Travel (0) < Travel_Rarely (1) < Travel_Frequently (2)

**Variables Nominales** (pas d'ordre - One-Hot Encoding) :
- `Department`, `EducationField`, `Gender`, `JobRole`, `MaritalStatus`

#### Gestion des Valeurs Manquantes

- Imputation par la moyenne pour les colonnes numÃ©riques

#### Double StratÃ©gie de Sortie

1. **`processed_hr_data_encoded_raw.csv`** (Non normalisÃ©)
   - Pour : Random Forest, XGBoost, interprÃ©tation mÃ©tier
   - Les valeurs restent rÃ©elles (salaire = 50000, Ã¢ge = 30)

2. **`processed_hr_data_encoded_normalized.csv`** (NormalisÃ© 0-1)
   - Pour : RÃ©seaux de Neurones, KNN, SVM, RÃ©gression Logistique
   - Toutes les valeurs entre 0 et 1 (MinMaxScaler)

---

## ğŸ“Š Analyse Exploratoire

Le notebook `Traitement.ipynb` gÃ©nÃ¨re 5 graphiques clÃ©s pour diagnostiquer les causes de dÃ©part :

### 1. Tableau Statistique (Heatmap)
- Affiche les statistiques descriptives (moyenne, mÃ©diane, min, max, Ã©cart-type)
- Exclut les variables binaires (0/1) pour se concentrer sur les numÃ©riques

### 2. RÃ©partition Globale (Countplot)
- VÃ©rifie le dÃ©sÃ©quilibre des classes
- Affiche le pourcentage de dÃ©parts vs restants

### 3. Taux de DÃ©part par MÃ©tier (Barplot)
- Identifie les mÃ©tiers les plus Ã  risque
- Calcul du taux : (DÃ©parts / Total) Ã— 100
- Tri dÃ©croissant pour mettre en avant les zones critiques

### 4. Heures de Travail (Boxplot)
- Compare la distribution des heures moyennes de travail
- CorrÃ©lation avec le burnout potentiel

### 5. AnciennetÃ© (KDE Plot)
- Visualise Ã  quel moment de la carriÃ¨re les employÃ©s partent
- Superposition des courbes (Rouge = DÃ©part, Bleu = Reste)

### 6. Matrice de CorrÃ©lation (Heatmap)
- Identifie les liens linÃ©aires forts avec l'attrition
- Focus sur les 10 premiÃ¨res variables numÃ©riques
- **Affichage optimisÃ©** : Ã‰tiquettes des colonnes en haut, rotÃ©es Ã  90Â°

---

## ğŸ¤– ModÃ¨les ImplÃ©mentÃ©s

Le notebook `Modele.ipynb` compare **9 modÃ¨les** de Machine Learning avec documentation complÃ¨te pour chacun :

### 1. RÃ©gression Logistique
- **Formule** : P(y=1|x) = 1 / (1 + e^(-(wÂ·x + b)))
- **Usage** : Classification binaire via fonction sigmoÃ¯de

### 2. Perceptron
- **Fonction** : f(x) = 1 si wÂ·x + b > 0, sinon 0
- **Usage** : Neurone artificiel simple

### 3. Support Vector Machine (SVM)
- **Principe** : Trace un hyperplan avec marge maximale
- **Usage** : SÃ©paration optimale des classes

### 4. K-Nearest Neighbors (KNN)
- **Principe** : Classification basÃ©e sur les K voisins les plus proches
- **Usage** : PrÃ©diction locale sans rÃ¨gle globale

### 5. Naive Bayes
- **Formule** : P(A|B) = P(B|A)Â·P(A) / P(B)
- **Usage** : ProbabilitÃ©s bayÃ©siennes avec hypothÃ¨se d'indÃ©pendance

### 6. Decision Tree
- **Principe** : Arbre de dÃ©cisions binaires successives
- **Usage** : RÃ¨gles de dÃ©cision interprÃ©tables

### 7. Random Forest
- **Principe** : Ensemble de centaines d'arbres votant collectivement
- **Usage** : Robustesse par agrÃ©gation (Bagging)

### 8. XGBoost
- **Principe** : Arbres successifs corrigeant les erreurs prÃ©cÃ©dentes
- **Usage** : Boosting pour performances maximales sur donnÃ©es tabulaires

### 9. RÃ©seau de Neurones (MLP)
- **Principe** : Couches de neurones interconnectÃ©s
- **Usage** : ModÃ©lisation de relations complexes non linÃ©aires

---

## ğŸ“ˆ MÃ©triques d'Ã‰valuation

### MÃ©triques Principales

- **Accuracy** : Taux de prÃ©dictions correctes global
- **Precision** : Proportion de vrais positifs parmi les prÃ©dits positifs
- **Recall** : Proportion de vrais positifs dÃ©tectÃ©s (critique pour l'attrition)
- **F1-Score** : Moyenne harmonique de Precision et Recall
- **AUC-ROC** : QualitÃ© globale du modÃ¨le (aire sous la courbe ROC)

### Validation CroisÃ©e (K-Fold)

- **CV Recall Moyen** : Moyenne des scores sur 5 splits diffÃ©rents
- **CV StabilitÃ©** : Ã‰cart-type pour Ã©valuer la robustesse

### PrÃ©vention du Surapprentissage

- âœ… Validation croisÃ©e (5-Fold Cross-Validation)
- âœ… SÃ©paration Train/Test (70/30 avec stratification)
- âœ… Techniques d'ensemble (Random Forest, XGBoost)
- âœ… `random_state=42` pour la reproductibilitÃ©

---

## ğŸ“Š Visualisations

### 1. Analyse des Facteurs d'Influence
- **Type** : Barplot de corrÃ©lations
- **Rouge** : Facteurs augmentant le dÃ©part (corrÃ©lation positive)
- **Vert** : Facteurs favorisant la rÃ©tention (corrÃ©lation nÃ©gative)

### 2. Matrices de Confusion (3Ã—3)
- Une matrice par modÃ¨le pour comparer les erreurs
- **Diagonale** : PrÃ©dictions correctes
- **Hors diagonale** : Faux positifs et faux nÃ©gatifs

### 3. Feature Importance
- **Source** : XGBoost ou Random Forest
- **Affichage** : Top 15 des variables les plus influentes
- **UtilitÃ©** : Identifier pourquoi les employÃ©s partent

---