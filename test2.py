import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import time
import warnings

# Imports Machine Learning
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression, Perceptron
from sklearn.svm import SVC
from sklearn.neural_network import MLPClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.naive_bayes import GaussianNB
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from xgboost import XGBClassifier
from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, accuracy_score, confusion_matrix

# On ignore les warnings inutiles
warnings.filterwarnings('ignore')

def charger_donnees(chemin):
    """Charge le fichier CSV."""
    print(f"üìÇ Chargement du fichier : {chemin}...")
    try:
        df = pd.read_csv(chemin)
        print(f" Donn√©es charg√©es : {df.shape[0]} lignes, {df.shape[1]} colonnes.")
        return df
    except FileNotFoundError:
        print(f" Erreur : Le fichier '{chemin}' est introuvable.")
        return None

def analyser_facteurs_influents(df):
    """
    Affiche les corr√©lations : 
    - Positives (Rouge) = Causes de d√©part
    - N√©gatives (Vert) = Raisons de rester
    """
    print("\n Analyse des facteurs d'influence (Corr√©lation)...")
    
    # Calcul des corr√©lations avec 'Attrition'
    # numeric_only=True √©vite les erreurs si des colonnes texte tra√Ænent
    corr = df.corr(numeric_only=True)['Attrition'].sort_values(ascending=False)
    
    # On retire la cible elle-m√™me (qui vaut 1)
    corr = corr.drop('Attrition', errors='ignore')
    
    # On prend le Top 10 positif (Partent) et Top 10 n√©gatif (Restent)
    top_positive = corr.head(10)
    top_negative = corr.tail(10)
    
    # On combine les deux pour le graphique
    top_corr = pd.concat([top_positive, top_negative])
    
    # Graphique
    plt.figure(figsize=(12, 8))
    # Couleur : Rouge si > 0 (D√©part), Vert si < 0 (Reste)
    colors = ['red' if x > 0 else 'green' for x in top_corr.values]
    sns.barplot(x=top_corr.values, y=top_corr.index, palette=colors)
    
    plt.title("Facteurs d'influence : Rouge = Fait partir | Vert = Fait rester")
    plt.xlabel("Corr√©lation")
    plt.axvline(x=0, color='black', linestyle='--')
    plt.show()

def preparation_donnees(df):
    """Pr√©pare les donn√©es pour l'IA (Split 70/30)."""
    print(" Pr√©paration des donn√©es (Train/Test Split)...")
    
    y = df['Attrition']
    X = df.drop('Attrition', axis=1)
    
    # stratify=y est important pour garder la m√™me proportion de d√©parts
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.3, random_state=42, stratify=y
    )
    
    return X_train, X_test, y_train, y_test, X.columns

def entrainer_modeles(X_train, X_test, y_train, y_test):
    """Entra√Æne une liste de mod√®les et compare les r√©sultats."""
    models = {
        "LogisticRegression": LogisticRegression(max_iter=1000, random_state=42),
        "Perceptron": Perceptron(random_state=42),
        "SVM": SVC(probability=True, random_state=42),
        "KNN": KNeighborsClassifier(),
        "NaiveBayes": GaussianNB(),
        "DecisionTree": DecisionTreeClassifier(random_state=42),
        "RandomForest": RandomForestClassifier(n_estimators=100, random_state=42),
        "XGBoost": XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42),
        "ReseauNeuronal": MLPClassifier(max_iter=500, random_state=42)
    }
    
    results = []
    trained_models = {}

    print("\n D√©but de l'entra√Ænement des mod√®les...")
    print("-" * 60)

    for name, model in models.items():
        start_time = time.time()
        model.fit(X_train, y_train)
        y_pred = model.predict(X_test)
        duration = time.time() - start_time
        
        # Calcul AUC si possible
        try:
            y_proba = model.predict_proba(X_test)[:, 1]
            auc = roc_auc_score(y_test, y_proba)
        except:
            auc = 0

        results.append({
            'Mod√®le': name,
            'Accuracy': accuracy_score(y_test, y_pred),
            'Precision': precision_score(y_test, y_pred),
            'Recall': recall_score(y_test, y_pred),
            'F1-Score': f1_score(y_test, y_pred),
            'AUC': auc,
            'Temps (s)': duration
        })
        
        trained_models[name] = model
        print(f"   üîπ {name:<20} | F1-Score: {f1_score(y_test, y_pred):.4f} | Temps: {duration:.3f}s")

    return pd.DataFrame(results), trained_models

def afficher_matrice_confusion(y_test, trained_models, X_test):
    """Affiche les matrices de confusion."""
    print("\nüìä G√©n√©ration des matrices de confusion...")
    plt.figure(figsize=(15, 10))
    
    for i, (name, model) in enumerate(trained_models.items()):
        y_pred = model.predict(X_test)
        cm = confusion_matrix(y_test, y_pred)
        
        plt.subplot(3, 3, i+1)
        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)
        plt.title(name)
        plt.ylabel('R√©el')
        plt.xlabel('Pr√©dit')
    
    plt.tight_layout()
    plt.show()

def afficher_importance_variables(trained_models, feature_names):
    """
    Affiche l'importance des variables pour le meilleur mod√®le 'Arbre' disponible.
    Ne privil√©gie pas XGBoost dans le nom, mais prend le plus performant.
    """
    # On cherche un mod√®le capable de donner l'importance (RandomForest ou XGBoost)
    model_choisi = None
    nom_modele = ""

    # On v√©rifie si XGBoost est l√†, sinon Random Forest
    if "XGBoost" in trained_models:
        model_choisi = trained_models["XGBoost"]
        nom_modele = "XGBoost"
    elif "RandomForest" in trained_models:
        model_choisi = trained_models["RandomForest"]
        nom_modele = "Random Forest"
    
    if model_choisi:
        print(f"\n Analyse des causes r√©elles du d√©part (Bas√© sur le mod√®le : {nom_modele})...")
        
        importances = model_choisi.feature_importances_
        feature_imp_df = pd.DataFrame({
            'Variable': feature_names,
            'Importance': importances
        }).sort_values(by='Importance', ascending=False).head(15)
        
        plt.figure(figsize=(10, 8))
        sns.barplot(x='Importance', y='Variable', data=feature_imp_df, palette='magma')
        plt.title(f"TOP 15 des variables les plus importantes ({nom_modele})")
        plt.xlabel("Poids dans la d√©cision")
        plt.show()
    else:
        print("Aucun mod√®le de type 'Arbre' (Tree) n'a √©t√© entra√Æn√© pour l'analyse d'importance.")

# --- MAIN ---
if __name__ == "__main__":
    # 1. Chemin du fichier (V√©rifie bien que c'est le bon !)
    fichier_csv = 'data/processed_hr_data_encoded_normalized.csv'
    
    # 2. Chargement
    df = charger_donnees(fichier_csv)
    
    if df is not None:
        # 3. Analyse Corr√©lation (Rouge vs Vert) - AVANT le split
        analyser_facteurs_influents(df)

        # 4. Pr√©paration
        X_train, X_test, y_train, y_test, feature_names = preparation_donnees(df)
        
        # 5. Entra√Ænement
        resultats_df, modeles_entraines = entrainer_modeles(X_train, X_test, y_train, y_test)
        
        # 6. R√©sultats
        print("\n CLASSEMENT FINAL (Tri√© par Recall & F1-Score) :")
        print(resultats_df.sort_values(by=['Recall', 'F1-Score'], ascending=False).to_string(index=False))
        
        # 7. Visualisations
        afficher_matrice_confusion(y_test, modeles_entraines, X_test)
        afficher_importance_variables(modeles_entraines, feature_names)